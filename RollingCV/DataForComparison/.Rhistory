rm(list = ls())
source('PlotFunctions.r')
ShowPlot = F
options.models = c('inputFiles/PredatorPrey.txt', 'inputFiles/RPS.txt',
'inputFiles/Chaotic_LV.txt')
length.training = 100
length.testing = 30
source('~/Desktop/Test/main.r', echo=TRUE)
rm(list = ls())
source('PlotFunctions.r')
ShowPlot = F
options.models = c('inputFiles/PredatorPrey.txt', 'inputFiles/RPS.txt',
'inputFiles/Chaotic_LV.txt')
length.training = 100
length.testing = 30
FileName = options.models[1]
### Read Time series
d = ReadTimeSeries(FileName)
### Use all the species
Embedding = LETTERS[1:ncol(d)]
TargetList = Embedding
######################
dfdx = expand.grid(TargetList, TargetList)
######################
d = d[, Embedding]
t.min = floor(runif(1,1, nrow(d) - length.training - length.testing-1))
length_of_interval = length.training + length.testing
t.max = t.min + length_of_interval - 1
interval = t.min:t.max
interval_training = 1:length.training
interval_testing = (length.training + 1):length_of_interval
#### Subset the chunk
d_intact = d[interval,]
d.training = d_intact[interval_training, ]
#### Make noise if you want
ObservationalNoise = 0
if(ObservationalNoise == 1){
d.training = d.training + matrix(rnorm(length(d.training), 0,mean(d.training)*0.05),
nrow(d.training), ncol(d.training))
cat('Added observational noise\n')
}
### Preserve the training set to standardize the test set
d.train.to.test.set = d.training
d.training = Standardizza(d.training)
#### The test set is only defined here after the predictions
d.testing = d_intact[interval_testing, ]
d.testing = Standardizza.test(d.testing,d.train.to.test.set)
par(mfrow = c(ncol(d.training), 1))
for(i in 1:ncol(d.training)){
Put_train_test_together(d.training[2:nrow(d.training),],d.testing,i)
}
par(mfrow = c(1,1))
############ For the plotting of the time series
Put_train_test_together <- function(d.tr, d.ts, species){
title = paste('Species', species)
plot(c(d.tr[,species],d.ts[,species]), pch = 20, ylim = c(-2,2),
main = title, ylab = expression('x'[species]))
abline(v=(nrow(d.tr)+1), col="blue", lty = 2, lwd = 1.5)
}
ReadTimeSeries <- function(Nome){
X = as.matrix(read.table(Nome, header = F))
colnames(X) =  LETTERS[1:ncol(X)]
return(X)
}
Standardizza <- function(X){
### This return y = (x-meanx)/stdx
for(i in 1:ncol(X)){
X[,i] = (X[,i]- mean(X[,i]))/sd(X[,i])
}
return(X)
}
Standardizza.test <- function(X, Y){
### X = test set
### Y = training set
### This return y = (x-meanY)/stdY
for(i in 1:ncol(X)){
X[,i] = (X[,i]- mean(Y[,i]))/sd(Y[,i])
}
return(X)
}
par(mfrow = c(ncol(d.training), 1))
for(i in 1:ncol(d.training)){
Put_train_test_together(d.training[2:nrow(d.training),],d.testing,i)
}
par(mfrow = c(1,1))
rm(list = ls())
source('PlotFunctions.r')
ShowPlot = F
options.models = c('inputFiles/PredatorPrey.txt', 'inputFiles/RPS.txt',
'inputFiles/Chaotic_LV.txt')
length.training = 100
length.testing = 30
FileName = options.models[3]
### Read Time series
d = ReadTimeSeries(FileName)
### Use all the species
Embedding = LETTERS[1:ncol(d)]
TargetList = Embedding
######################
dfdx = expand.grid(TargetList, TargetList)
######################
d = d[, Embedding]
t.min = floor(runif(1,1, nrow(d) - length.training - length.testing-1))
#### Random Chunk of length:
length_of_interval = length.training + length.testing
t.max = t.min + length_of_interval - 1
interval = t.min:t.max
interval_training = 1:length.training
interval_testing = (length.training + 1):length_of_interval
#### Subset the chunk
d_intact = d[interval,]
d.training = d_intact[interval_training, ]
#### Make noise if you want
ObservationalNoise = 0
if(ObservationalNoise == 1){
d.training = d.training + matrix(rnorm(length(d.training), 0,mean(d.training)*0.05),
nrow(d.training), ncol(d.training))
cat('Added observational noise\n')
}
### Preserve the training set to standardize the test set
d.train.to.test.set = d.training
d.training = Standardizza(d.training)
#### The test set is only defined here after the predictions
d.testing = d_intact[interval_testing, ]
d.testing = Standardizza.test(d.testing,d.train.to.test.set)
par(mfrow = c(ncol(d.training), 1))
for(i in 1:ncol(d.training)){
Put_train_test_together(d.training[2:nrow(d.training),],d.testing,i)
}
par(mfrow = c(1,1))
floor(runif(1,3))
runif(0,1)
floor(runif(1,1,3))
floor(runif(1,1,3))
floor(runif(1,1,3))
floor(runif(1,1,3))
floor(runif(1,1,3))
floor(runif(1,1,3))
floor(runif(1,1,3))
floor(runif(1,1,3))
floor(runif(1,1,3))
floor(runif(1,1,3))
floor(runif(1,1,3))
floor(runif(1,1,3))
floor(runif(1,1,3))
floor(runif(1,1,4))
floor(runif(1,1,4))
floor(runif(1,1,4))
floor(runif(1,1,4))
floor(runif(1,1,4))
rm(list = ls())
source('PlotFunctions.r')
options.models = c('inputFiles/PredatorPrey.txt', 'inputFiles/RPS.txt',
'inputFiles/Chaotic_LV.txt')
length.training = 100
length.testing = 30
for(k in 1:100){
##### Choose a random time series
FileName = options.models[floor(runif(1, 1, 4))]
### Read Time series
d = ReadTimeSeries(FileName)
### Use all the species
Embedding = LETTERS[1:ncol(d)]
TargetList = Embedding
######################
dfdx = expand.grid(TargetList, TargetList)
######################
d = d[, Embedding]
####
t.min = floor(runif(1,1, nrow(d) - length.training - length.testing-1))
#### Random Chunk of length:
length_of_interval = length.training + length.testing
t.max = t.min + length_of_interval - 1
interval = t.min:t.max
interval_training = 1:length.training
interval_testing = (length.training + 1):length_of_interval
#### Subset the chunk
d_intact = d[interval,]
d.training = d_intact[interval_training, ]
#### Make noise if you want
ObservationalNoise = 0
if(ObservationalNoise == 1){
d.training = d.training + matrix(rnorm(length(d.training), 0,mean(d.training)*0.05),
nrow(d.training), ncol(d.training))
cat('Added observational noise\n')
}
### Preserve the training set to standardize the test set
d.train.to.test.set = d.training
d.training = Standardizza(d.training)
#### The test set is only defined here after the predictions
d.testing = d_intact[interval_testing, ]
d.testing = Standardizza.test(d.testing,d.train.to.test.set)
to.save.training = paste('/TrainingData/TrainingData_Example_', k, '.txt', sep = '')
write.table(d.training, file = to.save, row.names = F, col.names = F)
to.save.testing = paste('/TestData/TestingData_Example_', k, '.txt', sep = '')
write.table(d.testing, file = to.save, row.names = F, col.names = F)
}
rm(list = ls())
source('PlotFunctions.r')
options.models = c('inputFiles/PredatorPrey.txt', 'inputFiles/RPS.txt',
'inputFiles/Chaotic_LV.txt')
length.training = 100
length.testing = 30
for(k in 1:100){
##### Choose a random time series
FileName = options.models[floor(runif(1, 1, 4))]
### Read Time series
d = ReadTimeSeries(FileName)
### Use all the species
Embedding = LETTERS[1:ncol(d)]
TargetList = Embedding
######################
dfdx = expand.grid(TargetList, TargetList)
######################
d = d[, Embedding]
####
t.min = floor(runif(1,1, nrow(d) - length.training - length.testing-1))
#### Random Chunk of length:
length_of_interval = length.training + length.testing
t.max = t.min + length_of_interval - 1
interval = t.min:t.max
interval_training = 1:length.training
interval_testing = (length.training + 1):length_of_interval
#### Subset the chunk
d_intact = d[interval,]
d.training = d_intact[interval_training, ]
#### Make noise if you want
ObservationalNoise = 0
if(ObservationalNoise == 1){
d.training = d.training + matrix(rnorm(length(d.training), 0,mean(d.training)*0.05),
nrow(d.training), ncol(d.training))
cat('Added observational noise\n')
}
### Preserve the training set to standardize the test set
d.train.to.test.set = d.training
d.training = Standardizza(d.training)
#### The test set is only defined here after the predictions
d.testing = d_intact[interval_testing, ]
d.testing = Standardizza.test(d.testing,d.train.to.test.set)
to.save.training = paste('/TrainingData/TrainingData_Example_', k, '.txt', sep = '')
write.table(d.training, file = to.save.training, row.names = F, col.names = F)
to.save.testing = paste('/TestData/TestingData_Example_', k, '.txt', sep = '')
write.table(d.testing, file = to.save.testing, row.names = F, col.names = F)
}
rm(list = ls())
source('PlotFunctions.r')
options.models = c('inputFiles/PredatorPrey.txt', 'inputFiles/RPS.txt',
'inputFiles/Chaotic_LV.txt')
length.training = 100
length.testing = 30
for(k in 1:100){
##### Choose a random time series
FileName = options.models[floor(runif(1, 1, 4))]
### Read Time series
d = ReadTimeSeries(FileName)
### Use all the species
Embedding = LETTERS[1:ncol(d)]
TargetList = Embedding
######################
dfdx = expand.grid(TargetList, TargetList)
######################
d = d[, Embedding]
####
t.min = floor(runif(1,1, nrow(d) - length.training - length.testing-1))
#### Random Chunk of length:
length_of_interval = length.training + length.testing
t.max = t.min + length_of_interval - 1
interval = t.min:t.max
interval_training = 1:length.training
interval_testing = (length.training + 1):length_of_interval
#### Subset the chunk
d_intact = d[interval,]
d.training = d_intact[interval_training, ]
#### Make noise if you want
ObservationalNoise = 0
if(ObservationalNoise == 1){
d.training = d.training + matrix(rnorm(length(d.training), 0,mean(d.training)*0.05),
nrow(d.training), ncol(d.training))
cat('Added observational noise\n')
}
### Preserve the training set to standardize the test set
d.train.to.test.set = d.training
d.training = Standardizza(d.training)
#### The test set is only defined here after the predictions
d.testing = d_intact[interval_testing, ]
d.testing = Standardizza.test(d.testing,d.train.to.test.set)
to.save.training = paste('TrainingData/TrainingData_Example_', k, '.txt', sep = '')
write.table(d.training, file = to.save.training, row.names = F, col.names = F)
to.save.testing = paste('TestData/TestingData_Example_', k, '.txt', sep = '')
write.table(d.testing, file = to.save.testing, row.names = F, col.names = F)
}
rm(list = ls())
source('PlotFunctions.r')
options.models = c('inputFiles/PredatorPrey.txt', 'inputFiles/RPS.txt',
'inputFiles/Chaotic_LV.txt')
length.training = 100
length.testing = 30
for(k in 1:100){
##### Choose a random time series
FileName = options.models[floor(runif(1, 1, 4))]
### Read Time series
d = ReadTimeSeries(FileName)
### Use all the species
Embedding = LETTERS[1:ncol(d)]
TargetList = Embedding
######################
dfdx = expand.grid(TargetList, TargetList)
######################
d = d[, Embedding]
####
t.min = floor(runif(1,1, nrow(d) - length.training - length.testing-1))
#### Random Chunk of length:
length_of_interval = length.training + length.testing
t.max = t.min + length_of_interval - 1
interval = t.min:t.max
interval_training = 1:length.training
interval_testing = (length.training + 1):length_of_interval
#### Subset the chunk
d_intact = d[interval,]
d.training = d_intact[interval_training, ]
#### Make noise if you want
ObservationalNoise = 1
if(ObservationalNoise == 1){
d.training = d.training + matrix(rnorm(length(d.training), 0,mean(d.training)*0.05),
nrow(d.training), ncol(d.training))
cat('Added observational noise\n')
}
### Preserve the training set to standardize the test set
d.train.to.test.set = d.training
d.training = Standardizza(d.training)
#### The test set is only defined here after the predictions
d.testing = d_intact[interval_testing, ]
d.testing = Standardizza.test(d.testing,d.train.to.test.set)
to.save.training = paste('TrainingData/TrainingData_Example_', k, '.txt', sep = '')
write.table(d.training, file = to.save.training, row.names = F, col.names = F)
to.save.testing = paste('TestData/TestingData_Example_', k, '.txt', sep = '')
write.table(d.testing, file = to.save.testing, row.names = F, col.names = F)
}
par(mfrow = c(ncol(d.training), 1))
for(i in 1:ncol(d.training)){
Put_train_test_together(d.training[2:nrow(d.training),],d.testing,i)
}
par(mfrow = c(1,1))
source('~/Desktop/Test/main.r')
source('~/Desktop/Test/main.r')
source('~/Desktop/Test/main.r')
source('~/Desktop/Test/main.r')
source('~/Desktop/Test/main.r')
source('~/Desktop/Test/main.r')
source('~/Desktop/Test/main.r')
source('~/Desktop/Test/main.r')
rm(list = ls())
source('PlotFunctions.r')
options.models = c('inputFiles/PredatorPrey.txt', 'inputFiles/RPS.txt',
'inputFiles/Chaotic_LV.txt')
length.training = 100
length.testing = 30
ObservationalNoise = T
cat('Observational Noise in training data:', ObservationalNoise)
for(k in 1:100){
##### Choose a random time series
FileName = options.models[floor(runif(1, 1, 4))]
### Read Time series
d = ReadTimeSeries(FileName)
### Use all the species
Embedding = LETTERS[1:ncol(d)]
TargetList = Embedding
######################
dfdx = expand.grid(TargetList, TargetList)
######################
d = d[, Embedding]
####
t.min = floor(runif(1,1, nrow(d) - length.training - length.testing-1))
#### Random Chunk of length:
length_of_interval = length.training + length.testing
t.max = t.min + length_of_interval - 1
interval = t.min:t.max
interval_training = 1:length.training
interval_testing = (length.training + 1):length_of_interval
#### Subset the chunk
d_intact = d[interval,]
d.training = d_intact[interval_training, ]
#### Make noise if you want
if(ObservationalNoise == T){
d.training = d.training + matrix(rnorm(length(d.training), 0,mean(d.training)*0.05),
nrow(d.training), ncol(d.training))
}
### Preserve the training set to standardize the test set
d.train.to.test.set = d.training
d.training = Standardizza(d.training)
#### The test set is only defined here after the predictions
d.testing = d_intact[interval_testing, ]
d.testing = Standardizza.test(d.testing,d.train.to.test.set)
to.save.training = paste('TrainingData/TrainingData_Example_', k, '.txt', sep = '')
write.table(d.training, file = to.save.training, row.names = F, col.names = F)
to.save.testing = paste('TestData/TestingData_Example_', k, '.txt', sep = '')
write.table(d.testing, file = to.save.testing, row.names = F, col.names = F)
}
par(mfrow = c(ncol(d.training), 1))
for(i in 1:ncol(d.training)){
Put_train_test_together(d.training[2:nrow(d.training),],d.testing,i)
}
par(mfrow = c(1,1))
source('~/Dropbox (MIT)/ToRun/DataForComparison/main.r')
